{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "import creds\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = creds.host\n",
    "password = creds.password\n",
    "port = creds.port\n",
    "user = creds.user\n",
    "database = creds.database\n",
    "api_type = creds.api_type\n",
    "engine = create_engine(f'postgresql+{api_type}://{user}:{password}@{host}:{port}/{database}')\n",
    "# engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table('products', engine)\n",
    "df.drop(['create_time', 'page_id'], axis=1, inplace=True)\n",
    "cvec = CountVectorizer()\n",
    "lab_enc = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning up the price column in the dataframe.\n",
    "# Removes all rows which have \"N/A\" in the price column.\n",
    "df = df[df['price'] != 'N/A']\n",
    "# df = df[df['product_name'] != 'N/A']\n",
    "df['price'] = df['price'].str.strip('£')\n",
    "df['price'] = df['price'].str.replace(',', '')\n",
    "df['price'] = df['price'].astype('float64')\n",
    "encoded = lab_enc.fit_transform(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in:\n",
      "    Training: 4794\n",
      "    Testing: 2362\n",
      "(4794, 3731)\n",
      "(4794,)\n",
      "(2362, 3731)\n",
      "(2362,)\n"
     ]
    }
   ],
   "source": [
    "X = df['product_name']\n",
    "y = encoded\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(\"Number of samples in:\")\n",
    "print(f\"    Training: {len(y_train)}\")\n",
    "print(f\"    Testing: {len(y_test)}\")\n",
    "# min_df=2 will remove all terms that only appear once in the entire data sheet. I assume them to be outliers or words that are never seen again.\n",
    "# cvec will transform all words into lowercase by default.\n",
    "cvec = CountVectorizer(min_df=2).fit(X_train)\n",
    "df_product_name_train = pd.DataFrame(cvec.transform(X_train).todense(),columns=cvec.get_feature_names_out())\n",
    "df_product_name_test = pd.DataFrame(cvec.transform(X_test).todense(),columns=cvec.get_feature_names_out())\n",
    "print(df_product_name_train.shape)\n",
    "print(y_train.shape)\n",
    "print(df_product_name_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12574089754445386"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(df_product_name_train, y_train)\n",
    "lr.score(df_product_name_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in:\n",
      "    Training: 4794\n",
      "    Testing: 2362\n",
      "(4794, 1465)\n",
      "(4794,)\n",
      "(2362, 1465)\n",
      "(2362,)\n"
     ]
    }
   ],
   "source": [
    "X = df['location']\n",
    "y = encoded\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(\"Number of samples in:\")\n",
    "print(f\"    Training: {len(y_train)}\")\n",
    "print(f\"    Testing: {len(y_test)}\")\n",
    "cvec = CountVectorizer(stop_words='english').fit(X_train)\n",
    "df_location_train = pd.DataFrame(cvec.transform(X_train).todense(),columns=cvec.get_feature_names_out())\n",
    "df_location_test = pd.DataFrame(cvec.transform(X_test).todense(),columns=cvec.get_feature_names_out())\n",
    "print(df_location_train.shape)\n",
    "print(y_train.shape)\n",
    "print(df_location_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08763759525825572"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(df_location_train, y_train)\n",
    "lr.score(df_location_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in:\n",
      "    Training: 4794\n",
      "    Testing: 2362\n",
      "(4794, 11871)\n",
      "(4794,)\n",
      "(2362, 11871)\n",
      "(2362,)\n"
     ]
    }
   ],
   "source": [
    "X = df['product_description']\n",
    "y = encoded\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(\"Number of samples in:\")\n",
    "print(f\"    Training: {len(y_train)}\")\n",
    "print(f\"    Testing: {len(y_test)}\")\n",
    "# min_df=2 will remove all terms that only appear once in the entire data sheet. I assume them to be outliers or words that are never seen again.\n",
    "# cvec will transform all words into lowercase by default.\n",
    "cvec = CountVectorizer(min_df=2).fit(X_train)\n",
    "df_product_description_train = pd.DataFrame(cvec.transform(X_train).todense(),columns=cvec.get_feature_names_out())\n",
    "df_product_description_test = pd.DataFrame(cvec.transform(X_test).todense(),columns=cvec.get_feature_names_out())\n",
    "print(df_product_description_train.shape)\n",
    "print(y_train.shape)\n",
    "print(df_product_description_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>003</th>\n",
       "      <th>0049437</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>0121</th>\n",
       "      <th>0141</th>\n",
       "      <th>01563</th>\n",
       "      <th>0161</th>\n",
       "      <th>...</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zips</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4794 rows × 11871 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  003  0049437  005  01  0121  0141  01563  0161  ...  yr  yrs  \\\n",
       "0      0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "1      0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "2      0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "3      0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "4      0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "...   ..  ...  ...      ...  ...  ..   ...   ...    ...   ...  ...  ..  ...   \n",
       "4789   0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "4790   0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "4791   0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "4792   0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "4793   0    0    0        0    0   0     0     0      0     0  ...   0    0   \n",
       "\n",
       "      zero  zip  zipped  zips  zombie  zone  zones  zoom  \n",
       "0        0    0       0     0       0     0      0     0  \n",
       "1        0    0       0     0       0     0      0     0  \n",
       "2        0    0       0     0       0     0      0     0  \n",
       "3        0    0       0     0       0     0      0     0  \n",
       "4        0    0       0     0       0     0      0     0  \n",
       "...    ...  ...     ...   ...     ...   ...    ...   ...  \n",
       "4789     0    0       0     0       0     0      0     0  \n",
       "4790     0    0       0     0       0     0      0     0  \n",
       "4791     0    0       0     0       0     0      0     0  \n",
       "4792     0    0       0     0       0     0      0     0  \n",
       "4793     0    0       0     0       0     0      0     0  \n",
       "\n",
       "[4794 rows x 11871 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_description_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1693480101608806"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(df_product_description_train, y_train)\n",
    "lr.score(df_product_description_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4794, 30571)\n",
      "(4794,)\n",
      "(2362, 30571)\n",
      "(2362,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([df_product_name_train, df_location_train, df_product_description_train], axis=1)\n",
    "test = pd.concat([df_product_name_test, df_location_test, df_product_description_test], axis=1)\n",
    "print(train.shape)\n",
    "print(y_train.shape)\n",
    "print(test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 36,  68, 104, ...,  36, 115,  99])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, y_train)\n",
    "# lr.score(test, y_test)\n",
    "lr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(2)\n",
    "\n",
    "# models = [\n",
    "#     DecisionTreeRegressor(splitter=\"random\"),\n",
    "#     SVR(),\n",
    "#     LinearRegression()\n",
    "#         ]\n",
    "\n",
    "# for model in models:\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     y_train_pred = model.predict(X_train)\n",
    "#     y_validation_pred = model.predict(X_validation)\n",
    "#     y_test_pred = model.predict(X_test)\n",
    "\n",
    "#     train_loss = mean_squared_error(y_train, y_train_pred)\n",
    "#     validation_loss = mean_squared_error(y_validation, y_validation_pred)\n",
    "#     test_loss = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "#     print(\n",
    "#         f\"{model.__class__.__name__}: \"\n",
    "#         f\"Train Loss: {train_loss} | Validation Loss: {validation_loss} | \"\n",
    "#         f\"Test Loss: {test_loss}\"\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
